# 類神經期中作業2 107201019 陳宇揚

## A
此作業我使用多層感知機實作

``` procesiing=1
class net {
  //初始化資料，有分為input,output和 hidden layers
  float learning_rate=0.1f;
  matrix input;
  matrix output;
  ArrayList<matrix> h;
  ArrayList<matrix> w;
  ArrayList<matrix> b;
  ArrayList<button> plus;
  ArrayList<button> minus;
  net(int i, int o) {
    h=new ArrayList<matrix>();
    w=new ArrayList<matrix>();
    b=new ArrayList<matrix>();
    plus=new ArrayList<button>();
    minus=new ArrayList<button>();
    input=new matrix(1, i);
    output=new matrix(1, o);
    w.add(new matrix(i, o));
    b.add(new matrix(1, o));
    for (matrix m : w) {
      m.init();
    }
    for (matrix m : b) {
      m.init();
    }
  }
  //可以根據使用者來挑整隱藏層層數跟數量
  public void plus(int i) {
    h.get(i).plus();
    b.get(i).plus();
    w.get(i).pluswf();   
    w.get(i+1).pluswb();
  }

  public void minus(int i) {
    if (n.h.get(i).rows>1) {
      h.get(i).minus();
      b.get(i).minus();
      w.get(i).minuswf();   
      w.get(i+1).minuswb();
    }
  }

  public void addhiddenlayer(int a) {
    //proggerm
    h.add(new matrix(1, a));
    w.clear();
    b.clear();
    plus.clear();
    minus.clear();
    for (int i=0; i<h.size()+1; i+=1) {      
      if (i==0) w.add(new matrix(input.rows, h.get(i).rows));
      else if (i==h.size()) w.add(new matrix(h.get(i-1).rows, output.rows));
      else w.add(new matrix(h.get(i-1).rows, h.get(i).rows));
    }
    for (int i=0; i<h.size(); i+=1) {
      b.add(new matrix(1, h.get(i).rows));
    }
    b.add(new matrix(1, output.rows));


    for (int i=0; i<h.size(); i+=1) {
      float r2=50;
      float h1=675+250*(i+1)/(n.h.size()+1);
      float l=250-(n.h.get(i).rows-1)*r2/2;
      plus.add(new button("+", h1, 50, 0, 20, 20));
      minus.add(new button("-", h1, 450, 0, 20, 20));
    }
    for (matrix m : w) {
      m.init();
    }
    for (matrix m : b) {
      m.init();
    }
  }

  public void clearhidden() {
    h.remove(h.size()-1);
    w.clear();
    b.clear();
    plus.clear();
    minus.clear();
    for (int i=0; i<h.size()+1; i+=1) { 
      if (h.size()==0) {
        w.add(new matrix(input.rows, output.rows));
        break;
      }
      if (i==0) w.add(new matrix(input.rows, h.get(i).rows));
      else if (i==h.size()) w.add(new matrix(h.get(i-1).rows, output.rows));
      else w.add(new matrix(h.get(i-1).rows, h.get(i).rows));
    }
    for (int i=0; i<h.size(); i+=1) {
      b.add(new matrix(1, h.get(i).rows));
    }
    b.add(new matrix(1, output.rows));
    //button
    for (int i=0; i<h.size(); i+=1) {
      float r2=50;
      float h1=675+250*(i+1)/(n.h.size()+1);
      float l=250-(n.h.get(i).rows-1)*r2/2;
      plus.add(new button("+", h1, 50, 0, 20, 20));
      minus.add(new button("-", h1, 450, 0, 20, 20));
    }
    for (matrix m : w) {
      m.init();
    }
    for (matrix m : b) {
      m.init();
    }
  }
  //正向傳播
  public float[] forward(drawpoint p) {
    input.w[0]=p.data.clone();
    if (h.size()==0) {
      output=input.multiple(w.get(0)).addiction(b.get(0)).sigmoidMatrix();
    } else {
      h.get(0).w=input.multiple(w.get(0)).addiction(b.get(0)).sigmoidMatrix().w.clone();
      for (int i=0; i<h.size()-1; i+=1) {
        h.get(i+1).w=h.get(i).multiple(w.get(i+1)).addiction(b.get(i+1)).sigmoidMatrix().w.clone();
      }
      output=h.get(h.size()-1).multiple(w.get(w.size()-1)).addiction(b.get(b.size()-1)).sigmoidMatrix();
    }


    return output.w[0].clone();
  }
  public float[] forward(float[] p) {
    input.w[0]=p.clone();
    if (h.size()==0) {
      output=input.multiple(w.get(0)).addiction(b.get(0)).sigmoidMatrix();
    } else {
      h.get(0).w=input.multiple(w.get(0)).addiction(b.get(0)).sigmoidMatrix().w.clone();
      for (int i=0; i<h.size()-1; i+=1) {
        h.get(i+1).w=h.get(i).multiple(w.get(i+1)).addiction(b.get(i+1)).sigmoidMatrix().w.clone();
      }
      output=h.get(h.size()-1).multiple(w.get(w.size()-1)).addiction(b.get(b.size()-1)).sigmoidMatrix();
    }


    return output.w[0].clone();
  }
  //反向傳播
  public void train(drawpoint p) {
    //println(output.w[0]);
    if (h.size()==0) {
      matrix outputs=output;
      matrix target=new matrix(1, output.rows);
      target.w[0]=p.lable.clone();
      matrix output_error=target.subtract(outputs);
      
      outputs=outputs.dsigmoidMatrix().scalematrix(output_error).scalematrix(learning_rate);
      
      matrix input_t=input.transport();
      
      matrix w_delta=input_t.multiple(outputs);
           
      w.get(0).w=w.get(0).addiction(w_delta).w.clone();
      b.get(0).w=b.get(0).addiction(outputs).w.clone();
    }
    else{
      //output to last
      matrix outputs=output;
      matrix target=new matrix(1,output.rows);
      target.w[0]=p.lable.clone();
      matrix output_error=target.subtract(outputs);
      outputs=outputs.dsigmoidMatrix().scalematrix(output_error).scalematrix(learning_rate);
      
      matrix h_t=h.get(h.size()-1).transport();
      matrix w_delta=h_t.multiple(outputs);
      w.get(w.size()-1).w=w.get(w.size()-1).addiction(w_delta).w.clone();
      b.get(b.size()-1).w=b.get(b.size()-1).addiction(outputs).w.clone();
      
      matrix wl_t=w.get(w.size()-1).transport();
      matrix h_error=output_error.multiple(wl_t);
      // hidden
      for(int i=h.size()-1;i>0;i-=1){
        matrix hh=h.get(i);
        hh=hh.dsigmoidMatrix().scalematrix(h_error).scalematrix(learning_rate);
        
        h_t=h.get(i-1).transport();
        w_delta=h_t.multiple(hh);
        w.get(i).w=w.get(i).addiction(w_delta).w.clone();
        b.get(i).w=b.get(i).addiction(hh).w.clone();
        
        wl_t=w.get(i).transport();
        h_error=h_error.multiple(wl_t);
        
    }      
      // first to input
      matrix hh=h.get(0);
      
      hh=hh.dsigmoidMatrix().scalematrix(h_error).scalematrix(learning_rate);
      
      matrix i_t=input.transport();
      w_delta=i_t.multiple(hh);
      w.get(0).w=w.get(0).addiction(w_delta).w.clone();
      b.get(0).w=b.get(0).addiction(hh).w.clone();
    }
    
  }


  public void addhidden() {
  }
}
```
## B

![](https://codimd.mcl.math.ncu.edu.tw/uploads/upload_ae81c87986c11cd30c88f0e64534ed42.png)

![](https://codimd.mcl.math.ncu.edu.tw/uploads/upload_a588dda146ecf3077874e736bf359f74.png)

![](https://codimd.mcl.math.ncu.edu.tw/uploads/upload_00ef6d6b578979c0abfad330ee052b57.png)

![](https://codimd.mcl.math.ncu.edu.tw/uploads/upload_b0b8504ff68a49284676351043c704da.png)




## C

### perpectron1
訓練次數:322 學習率:0.217 層數:(2,6,2)
![](https://codimd.mcl.math.ncu.edu.tw/uploads/upload_673970b5df9873848d2fef783da74e67.png)

#### 結果
<img src='https://codimd.mcl.math.ncu.edu.tw/uploads/upload_7b80a2749deaf82f77b0611d6f9f0928.png'>

<img src='https://codimd.mcl.math.ncu.edu.tw/uploads/upload_580120e2b81079cec5d5278100be165b.png' >

### perceptron2
訓練次數:322 學習率:0.217 層數:(2,6,2)
![](https://codimd.mcl.math.ncu.edu.tw/uploads/upload_ceb7f7ed0de1b610a92b3df8b92005dd.png)
#### 結果
![](https://codimd.mcl.math.ncu.edu.tw/uploads/upload_87ee140d6d9b8313d63d9e5ed3292e68.png)
![](https://codimd.mcl.math.ncu.edu.tw/uploads/upload_88fdb9026ae9d7abc015147b33c4393d.png)

### Ccircle1
訓練次數:5357 學習率:0.014 層數:(2,7,2)
![](https://codimd.mcl.math.ncu.edu.tw/uploads/upload_72a215a37253a2d341622e4f0aa29eb9.png)
#### 結果
![](https://codimd.mcl.math.ncu.edu.tw/uploads/upload_024cabb1ec561266bb36e81e1f85a2e6.png)
![](https://codimd.mcl.math.ncu.edu.tw/uploads/upload_44724e65da41f38b72cce0c49aeda872.png)

### Circle1
訓練次數:5357 學習率:0.014 層數:(2,7,2)

![](https://codimd.mcl.math.ncu.edu.tw/uploads/upload_c79e24e6297174688542243a057335c5.png)
#### 結果
![](https://codimd.mcl.math.ncu.edu.tw/uploads/upload_0f7db6db71c8153f56bba2fa6f26f1b3.png)
![](https://codimd.mcl.math.ncu.edu.tw/uploads/upload_3268e91dfab340df98ce938d87943954.png)
### Circle2
訓練次數:5357 學習率:0.014 層數:(2,7,2)
![](https://codimd.mcl.math.ncu.edu.tw/uploads/upload_3bd9b8701478a19f372f3ab7389139ee.png)

#### 結果
![](https://codimd.mcl.math.ncu.edu.tw/uploads/upload_13f46b006eca61a4c8468c1cdc1ac617.png)
![](https://codimd.mcl.math.ncu.edu.tw/uploads/upload_baa00db816381c7a6b31d8dffc016988.png)
### 2CloseS
訓練次數:429 學習率:0.11 層數:(2,6,2)
![](https://codimd.mcl.math.ncu.edu.tw/uploads/upload_8ebd171ba815066942ea53c988580bc3.png)
#### 結果
![](https://codimd.mcl.math.ncu.edu.tw/uploads/upload_2423d833e1bb96f7210ffe12314dc4e3.png)
![](https://codimd.mcl.math.ncu.edu.tw/uploads/upload_75c64c786479f259c9b3f71b2df9c8cf.png)
### 2CloseS2
訓練次數:429 學習率:0.11 層數:(2,6,2)
![](https://codimd.mcl.math.ncu.edu.tw/uploads/upload_141c9473617b0466a18b4c662bac9389.png)
#### 結果
![](https://codimd.mcl.math.ncu.edu.tw/uploads/upload_02665238442f5e29228b73e777e14f14.png)
![](https://codimd.mcl.math.ncu.edu.tw/uploads/upload_a7a3fac60902e97714f5f2745904852a.png)

### 2CloseS3
訓練次數:1786 學習率:0.11 層數:(2,7,2)
![](https://codimd.mcl.math.ncu.edu.tw/uploads/upload_c45e336b99b95077091f58783bce6359.png)
### 結果
![](https://codimd.mcl.math.ncu.edu.tw/uploads/upload_a19a4c1079924922fc0bc42b28f168b8.png)
![](https://codimd.mcl.math.ncu.edu.tw/uploads/upload_d9b8ca4eda6fee2bf048d11fcee21216.png)
### 2cring 
訓練次數:143 學習率:0.11 層數:(2,6,2)

### 結果
![](https://codimd.mcl.math.ncu.edu.tw/uploads/upload_3d5952e62a07111f0ee866b03d9a9932.png)
![](https://codimd.mcl.math.ncu.edu.tw/uploads/upload_161833892f8372bac9fafa76c0eccf0a.png)

### 2CS
訓練次數:143 學習率:0.11 層數:(2,6,2)
![](https://codimd.mcl.math.ncu.edu.tw/uploads/upload_bf22efb0ffcf5ce570c6db89d229114f.png)
### 結果
![](https://codimd.mcl.math.ncu.edu.tw/uploads/upload_a13484f969d9f2f779b70609e29ed853.png)
![](https://codimd.mcl.math.ncu.edu.tw/uploads/upload_dd21fb45744b38499ec047f61f05893e.png)
### 2Hcircle1
訓練次數:143 學習率:0.11 層數:(2,6,2)
![](https://codimd.mcl.math.ncu.edu.tw/uploads/upload_355d7d0fd179dba4c7e2d577dc794b47.png)
![](https://codimd.mcl.math.ncu.edu.tw/uploads/upload_0c9f0a7915f379a9d4f326b55e1d42bf.png)
### 2ring
訓練次數:143 學習率:0.11 層數:(2,6,2)
![](https://codimd.mcl.math.ncu.edu.tw/uploads/upload_00bf23b2db886062469a4a5ad05bd41d.png)
![](https://codimd.mcl.math.ncu.edu.tw/uploads/upload_9031a2e2044c6886adcfc22adde9354e.png)


## D 分析

可以看到，如果原本數據很分得很開，網路的訓練就非常快，而且準確率可以達到100%;但是數據若緊密貼合，他的訓練時間會拉很長，但還是可以訓練得還不錯，都有達到90%以上(Circle2除外)。

## E

1. 隱藏層層數可設定
2. 隱藏層的神經元個數可設定
3. 手寫辨識



